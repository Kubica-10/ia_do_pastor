import os
import streamlit as st
from dotenv import load_dotenv
from supabase import create_client, Client
import bcrypt
import json # Para ler o biblia_completa.json

# --- Importa√ß√£o para PDF (com sintaxe moderna) ---
from fpdf import FPDF, XPos, YPos

# --- Importa√ß√µes do agente (LangChain, etc.) ---
from langchain_groq import ChatGroq
from langchain.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# --- NOVAS IMPORTA√á√ïES PARA FERRAMENTAS E AGENTES ---
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.tools import tool # Importa o decorador @tool

# --- IMPORTA√á√ÉO DO SYSTEM_PROMPT DO ARQUIVO prompts.py ---
from prompts import SYSTEM_PROMPT

# --- Configura√ß√£o Inicial ---
st.set_page_config(page_title="Assistente de Prega√ß√£o - IA", page_icon="üìñ", layout="wide")
load_dotenv()

# --- DEFINI√á√ÉO DAS FUN√á√ïES PRINCIPAIS DO APP ---
FAISS_INDEX_PATH = "faiss_index"
BIBLIA_COMPLETA_PATH = "biblia_completa.json" # Caminho para o seu arquivo da B√≠blia completa

# Carrega a B√≠blia completa para a ferramenta de cita√ß√£o
try:
    with open(BIBLIA_COMPLETA_PATH, 'r', encoding='utf-8') as f:
        BIBLIA_COMPLETA = json.load(f)
except FileNotFoundError:
    st.error(f"ERRO: O arquivo '{BIBLIA_COMPLETA_PATH}' n√£o foi encontrado. Por favor, certifique-se de que ele est√° na mesma pasta do 'main.py'.")
    st.stop()
except json.JSONDecodeError:
    st.error(f"ERRO: O arquivo '{BIBLIA_COMPLETA_PATH}' est√° corrompido ou mal formatado. Verifique o conte√∫do JSON.")
    st.stop()

# --- FERRAMENTA DE CITA√á√ÉO B√çBLICA (SUA IDEIA IMPLEMENTADA!) ---
@tool
def citar_biblia(referencia: str) -> str:
    """
    Usa esta ferramenta para obter o texto EXATO de um vers√≠culo b√≠blico.
    O formato da refer√™ncia DEVE ser: 'Livro Cap√≠tulo:Vers√≠culo'.
    Exemplos: '√äxodo 3:14', 'Salmos 23:1', 'Jo√£o 3:16'.
    Retorna o texto do vers√≠culo ou uma mensagem de 'vers√≠culo n√£o encontrado'.
    """
    try:
        livro_cap_vers = referencia.split(' ', 1) # Separa o Livro do restante
        livro = livro_cap_vers[0]

        if len(livro_cap_vers) < 2:
            return f"Refer√™ncia '{referencia}' inv√°lida. Formato esperado: 'Livro Cap√≠tulo:Vers√≠culo'."

        capitulo_versiculo = livro_cap_vers[1]

        # Adapta√ß√£o para o formato do seu JSON, se for diferente de "Livro C:V"
        # Assumindo que seu JSON tem a estrutura:
        # { "Livro": { "Capitulo": { "Versiculo": "Texto" } } }
        # Ou diretamente: { "Livro C:V": "Texto" }
        # Se for diretamente "Livro C:V": "Texto", a busca √© mais simples.
        # VAMOS ASSUMIR POR AGORA QUE √â "Livro C:V": "Texto" (a chave √© a refer√™ncia completa)

        # Busca direta pela refer√™ncia completa no JSON
        versiculo_texto = BIBLIA_COMPLETA.get(referencia, None)

        if versiculo_texto:
            return versiculo_texto
        else:
            return f"Vers√≠culo '{referencia}' n√£o encontrado na base de dados da B√≠blia. Por favor, verifique a refer√™ncia exata."
    except Exception as e:
        return f"Erro ao tentar citar a B√≠blia com a refer√™ncia '{referencia}': {e}. Certifique-se do formato 'Livro Cap√≠tulo:Vers√≠culo'."

# --- Fun√ß√µes existentes do app ---
def gerar_pdf_da_conversa(historico_chat):
    pdf = FPDF()
    pdf.add_page()
    try:
        pdf.add_font('DejaVu', '', 'DejaVuSans.ttf')
        pdf.set_font('DejaVu', '', 12)
    except FileNotFoundError:
        st.warning("Fonte 'DejaVuSans.ttf' n√£o encontrada. Usando Helvetica.")
        pdf.set_font('Helvetica', '', 12)

    pdf.cell(0, 10, 'Serm√£o Gerado pelo Assistente de Prega√ß√£o IA', new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C')
    pdf.ln(10)

    for mensagem in historico_chat:
        role = "Usu√°rio" if mensagem['role'] == 'user' else "Assistente de IA"
        content = mensagem['content'].encode('latin-1', 'replace').decode('latin-1')
        pdf.multi_cell(0, 10, f"{role}: {content}")
        pdf.ln(5)

    return bytes(pdf.output())

@st.cache_resource(show_spinner="Carregando base de conhecimento...")
def carregar_base_de_conhecimento():
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")
    if os.path.exists(FAISS_INDEX_PATH):
        return FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    return None

# --- NOVA FUN√á√ÉO PARA CRIAR A CADEIA DE AGENTE ---
def criar_cadeia_de_agente(_vectorstore):
    llm = ChatGroq(model='llama-3.1-8b-instant', temperature=0.7) # Voltamos ao 8b

    # Agora o Agente ter√° acesso √†s ferramentas
    tools = [
        citar_biblia, # Nossa nova ferramenta!
        # Podemos adicionar mais ferramentas aqui no futuro, se necess√°rio.
    ]

    # O Agente precisar√° do retriever como uma 'tool' impl√≠cita para o RAG
    # Para isso, usaremos o vectorstore diretamente na constru√ß√£o do agente
    # A instru√ß√£o para usar o RAG estar√° no SYSTEM_PROMPT.

    # Cria o prompt do agente, que inclui as instru√ß√µes e o chat history
    # O SYSTEM_PROMPT (agora em prompts.py) ser√° injetado aqui.
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT), # O SYSTEM_PROMPT cont√©m as instru√ß√µes para o agente usar as ferramentas e o RAG
        ("placeholder", "{chat_history}"), # Placeholder para o hist√≥rico da conversa
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"), # Onde o agente "rascunha" seu racioc√≠nio e uso de ferramentas
    ])

    # Cria o agente que sabe como usar as ferramentas
    agent = create_tool_calling_agent(llm, tools, prompt)

    # Cria o executor do agente. Este √© o cora√ß√£o do sistema.
    # Ele orquestra o LLM, as ferramentas e o retriever (para RAG).
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True, # Define como True para ver o racioc√≠nio do agente no console/logs
        # O RAG agora ser√° parte do que o Agente "pensa" em usar, instru√≠do pelo SYSTEM_PROMPT
        # N√£o passamos o retriever diretamente aqui, mas o prompt guiar√° o agente a usar
        # o CONTEXTO B√çBLICO PARA CONSULTA RIGOROSA (RAG) para informa√ß√µes gerais,
        # e a 'citar_biblia' para cita√ß√µes LITERAIS.
    )

# --- CONFIGURA√á√ÉO DE AUTENTICA√á√ÉO E BANCO DE DADOS ---
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("ERRO: As chaves do Supabase (SUPABASE_URL, SUPABASE_KEY) n√£o foram encontradas no arquivo .env.")
    st.stop()

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Inicializa√ß√£o segura do session_state
if 'authentication_status' not in st.session_state:
    st.session_state['authentication_status'] = None
if 'name' not in st.session_state:
    st.session_state['name'] = None

# --- L√ìGICA DE AUTENTICA√á√ÉO ---
if not st.session_state['authentication_status']:
    st.title("üìñ Assistente de Prega√ß√£o - IA")
    choice = st.selectbox("Acessar ou Criar Conta", ["Login", "Criar Conta"])

    if choice == "Login":
        with st.form("login_form"):
            email = st.text_input("Email")
            password = st.text_input("Senha", type="password")
            if st.form_submit_button("Login", type="primary"):
                try:
                    user_data = supabase.table("users").select("*").eq("email", email).execute().data
                    if user_data:
                        user = user_data[0]
                        if bcrypt.checkpw(password.encode('utf-8'), user["password"].encode('utf-8')):
                            st.session_state['authentication_status'] = True
                            st.session_state['name'] = user['name']
                            st.rerun()
                        else:
                            st.error("Email ou senha incorreto.")
                    else:
                        st.error("Email ou senha incorreto.")
                except Exception as e:
                    st.error(f"Erro de conex√£o com o banco de dados: {e}")

    elif choice == "Criar Conta":
        with st.form("register_form"):
            new_name = st.text_input("Nome")
            new_email = st.text_input("Email")
            new_password = st.text_input("Senha", type="password")
            if st.form_submit_button("Criar Conta", type="primary"):
                if new_name and new_email and new_password:
                    try:
                        existing = supabase.table("users").select("email").eq("email", new_email).execute().data
                        if existing:
                            st.error("Este email j√° est√° cadastrado!")
                        else:
                            hashed_password = bcrypt.hashpw(new_password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
                            supabase.table("users").insert({"name": new_name, "email": new_email, "password": hashed_password}).execute()
                            st.success("Conta criada com sucesso! Por favor, fa√ßa o login.")
                            st.balloons()
                    except Exception as e:
                        st.error(f"Erro ao criar conta: {e}")
                else:
                    st.warning("Por favor, preencha todos os campos.")

# --- L√ìGICA DO CHATBOT AP√ìS AUTENTICA√á√ÉO ---
if st.session_state['authentication_status']:
    st.title(f"üìñ Assistente de Prega√ß√£o - Ol√°, {st.session_state['name']}!")

    def limpar_conversa():
        st.session_state.chat_history = []

    with st.sidebar:
        if st.button("Sair"):
            for key in st.session_state.keys():
                del st.session_state[key]
            st.rerun()
        st.divider()

        if "chat_history" in st.session_state and st.session_state.chat_history:
            st.header("A√ß√µes da Conversa")
            pdf_data = gerar_pdf_da_conversa(st.session_state.chat_history)
            st.download_button(label="‚¨áÔ∏è Baixar (PDF)", data=pdf_data, file_name="serm√£o_gerado.pdf", mime="application/pdf")
            imprimir_js = "<script>function printPage() { window.print(); }</script><button onclick='printPage()'>üñ®Ô∏è Imprimir</button>"
            st.markdown(imprimir_js, unsafe_allow_html=True)
            st.button("üóëÔ∏è Limpar", on_click=limpar_conversa)

    vectorstore = carregar_base_de_conhecimento()

    if vectorstore:
        if "conversation_agent" not in st.session_state:
            st.session_state.conversation_agent = criar_cadeia_de_agente(vectorstore)

        st.info("Estou pronto. Fa√ßa uma pergunta ou pe√ßa para criar um serm√£o.")

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        user_query = st.chat_input("Ex: 'Crie um serm√£o sobre f√© e perseveran√ßa'")
        if user_query:
            st.session_state.chat_history.append({"role": "user", "content": user_query})
            with st.chat_message("user"):
                st.markdown(user_query)

            with st.chat_message("assistant"):
                with st.spinner("Estruturando a mensagem com o Poder do Esp√≠rito Santo..."):
                    # Agora, invocar o Agente
                    response = st.session_state.conversation_agent.invoke(
                        {"input": user_query, "chat_history": st.session_state.chat_history} # Passa o hist√≥rico para o agente
                    )
                    st.write(response["output"]) # O output do Agente √© 'output', n√£o 'answer'
            st.session_state.chat_history.append({"role": "assistant", "content": response["output"]})
            st.rerun()
    else:
        st.error("ERRO CR√çTICO: A base de conhecimento (pasta 'faiss_index') n√£o foi encontrada ou est√° corrompida.")
        st.warning("Por favor, garanta que o script 'treinar_ia.py' foi executado com sucesso e que o modelo de embedding no main.py corresponde ao modelo usado no treinamento.")